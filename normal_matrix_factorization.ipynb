{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/get_movies.pkl', 'rb') as f:\n",
    "    t = pickle.load(f)\n",
    "    \n",
    "movie_dic = t[0]\n",
    "movie_genre_dic = t[1]\n",
    "\n",
    "with open('data/get_ratings.pkl', 'rb') as f:\n",
    "    lst = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_A(Ui, Yij, Vj, a, b, reg, eta):\n",
    "    \"\"\"\n",
    "    Takes as input Ui (the ith row of U), a training point Yij, the column\n",
    "    vector Vj (jth column of V^T), reg (the regularization parameter lambda),\n",
    "    and eta (the learning rate).\n",
    "\n",
    "    Returns the updated value of a (by updating by eta times the gradient with respect to a).\n",
    "    \"\"\"\n",
    "    return (1-reg*eta)*a + eta * (Yij - np.dot(Ui,Vj) - a - b)\n",
    "\n",
    "def grad_B(Ui, Yij, Vj, a, b, reg, eta):\n",
    "    \"\"\"\n",
    "    Takes as input Ui (the ith row of U), a training point Yij, the column\n",
    "    vector Vj (jth column of V^T), reg (the regularization parameter lambda),\n",
    "    and eta (the learning rate).\n",
    "\n",
    "    Returns the updated value of a (by updating by eta times the gradient with respect to a).\n",
    "    \"\"\"\n",
    "    return (1-reg*eta)*b + eta * (Yij - np.dot(Ui,Vj) - a - b)\n",
    "\n",
    "def grad_U(Ui, Yij, Vj, a, b, reg, eta):\n",
    "    \"\"\"\n",
    "    Takes as input Ui (the ith row of U), a training point Yij, the column\n",
    "    vector Vj (jth column of V^T), reg (the regularization parameter lambda),\n",
    "    and eta (the learning rate).\n",
    "\n",
    "    Returns the gradient of the regularized loss function with\n",
    "    respect to Ui multiplied by eta.\n",
    "    \"\"\"\n",
    "    return (1-reg*eta)*Ui + eta * Vj * (Yij - np.dot(Ui,Vj) - a - b)\n",
    "\n",
    "def grad_V(Vj, Yij, Ui, a, b, reg, eta):\n",
    "    \"\"\"\n",
    "    Takes as input the column vector Vj (jth column of V^T), a training point Yij,\n",
    "    Ui (the ith row of U), reg (the regularization parameter lambda),\n",
    "    and eta (the learning rate).\n",
    "\n",
    "    Returns the gradient of the regularized loss function with\n",
    "    respect to Vj multiplied by eta.\n",
    "    \"\"\"\n",
    "    return (1-reg*eta)*Vj + eta * Ui * (Yij - np.dot(Ui,Vj) - a - b)\n",
    "\n",
    "def get_err(U, V, Y, reg=0.0):\n",
    "    \"\"\"\n",
    "    Takes as input a matrix Y of triples (i, j, Y_ij) where i is the index of a user,\n",
    "    j is the index of a movie, and Y_ij is user i's rating of movie j and\n",
    "    user/movie matrices U and V.\n",
    "\n",
    "    Returns the mean regularized squared-error of predictions made by\n",
    "    estimating Y_{ij} as the dot product of the ith row of U and the jth column of V^T.\n",
    "    \"\"\"\n",
    "    # Compute mean squared error on each data point in Y; include\n",
    "    # regularization penalty in error calculations.\n",
    "    # We first compute the total squared squared error\n",
    "    err = 0.0\n",
    "    for (i,j,Yij) in Y:\n",
    "        err += 0.5 *(Yij - np.dot(U[i-1], V[:,j-1]))**2\n",
    "    # Add error penalty due to regularization if regularization\n",
    "    # parameter is nonzero\n",
    "    if reg != 0:\n",
    "        U_frobenius_norm = np.linalg.norm(U, ord='fro')\n",
    "        V_frobenius_norm = np.linalg.norm(V, ord='fro')\n",
    "        err += 0.5 * reg * (U_frobenius_norm ** 2)\n",
    "        err += 0.5 * reg * (V_frobenius_norm ** 2)\n",
    "    # Return the mean of the regularized error\n",
    "    return err / float(len(Y))\n",
    "\n",
    "def train_model(M, N, K, eta, reg, Y, eps=0.0001, max_epochs=300):\n",
    "    \"\"\"\n",
    "    Given a training data matrix Y containing rows (i, j, Y_ij)\n",
    "    where Y_ij is user i's rating on movie j, learns an\n",
    "    M x K matrix U and N x K matrix V such that rating Y_ij is approximated\n",
    "    by (UV)_ij.\n",
    "\n",
    "    Uses a learning rate of <eta> and regularization of <reg>. Stops after\n",
    "    <max_epochs> epochs, or once the magnitude of the decrease in regularized\n",
    "    MSE between epochs is smaller than a fraction <eps> of the decrease in\n",
    "    MSE after the first epoch.\n",
    "\n",
    "    Returns a tuple (U, V, err) consisting of U, V, and the unregularized MSE\n",
    "    of the model.\n",
    "    \"\"\"\n",
    "    # Initialize U, V, A, B\n",
    "    U = np.random.random((M,K)) - 0.5\n",
    "    V = np.random.random((K,N)) - 0.5\n",
    "    \n",
    "#     A = np.random.random((M,1)) * 0.01 - 0.005\n",
    "#     B = np.random.random((1,N)) * 0.01 - 0.005\n",
    "\n",
    "    A = np.random.random((M,1)) * 0\n",
    "    B = np.random.random((1,N)) * 0\n",
    "\n",
    "\n",
    "    size = len(Y)\n",
    "    delta = None\n",
    "    indices = np.arange(size)    \n",
    "    for epoch in range(max_epochs):\n",
    "        # Run an epoch of SGD\n",
    "        before_E_in = get_err(U, V, Y, reg)\n",
    "        np.random.shuffle(indices)\n",
    "        for ind in indices:\n",
    "            (i,j, Yij) = Y[ind]\n",
    "            # Update U[i], V[j]\n",
    "            U[i-1] = grad_U(U[i-1], Yij, V[:,j-1], A[i-1], B[:,j-1], reg, eta)\n",
    "            V[:,j-1] = grad_V(V[:,j-1], Yij, U[i-1], A[i-1], B[:,j-1], reg, eta)\n",
    "            \n",
    "            A[i-1] = grad_A(U[i-1], Yij, V[:,j-1], A[i-1], B[:,j-1], reg, eta)\n",
    "            B[:,j-1] = grad_B(V[:,j-1], Yij, U[i-1], A[i-1], B[:,j-1], reg, eta)\n",
    "            \n",
    "        # At end of epoch, print E_in\n",
    "        E_in = get_err(U, V, Y, reg)\n",
    "        print(\"Epoch %s, E_in (regularized MSE): %s\"%(epoch + 1, E_in))\n",
    "\n",
    "        # Compute change in E_in for first epoch\n",
    "        if epoch == 0:\n",
    "            delta = before_E_in - E_in\n",
    "\n",
    "        # If E_in doesn't decrease by some fraction <eps>\n",
    "        # of the initial decrease in E_in, stop early            \n",
    "        elif before_E_in - E_in < eps * delta:\n",
    "            break\n",
    "    return (U, V, get_err(U, V, Y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_movies = len(movie_dic)\n",
    "num_users = 943"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = num_users\n",
    "n = num_movies\n",
    "k = 20\n",
    "eta = 0.1\n",
    "reg = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = np.array(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, E_in (regularized MSE): 5.26254539991349\n",
      "Epoch 2, E_in (regularized MSE): 4.512113282723599\n",
      "Epoch 3, E_in (regularized MSE): 3.84444396818163\n",
      "Epoch 4, E_in (regularized MSE): 3.377947642769085\n",
      "Epoch 5, E_in (regularized MSE): 2.942620761094713\n",
      "Epoch 6, E_in (regularized MSE): 2.6098254998297383\n",
      "Epoch 7, E_in (regularized MSE): 2.3733078922062947\n",
      "Epoch 8, E_in (regularized MSE): 2.1381939237819294\n",
      "Epoch 9, E_in (regularized MSE): 1.9218384132144248\n",
      "Epoch 10, E_in (regularized MSE): 1.7342440754841482\n",
      "Epoch 11, E_in (regularized MSE): 1.605809232716293\n",
      "Epoch 12, E_in (regularized MSE): 1.4709857340575199\n",
      "Epoch 13, E_in (regularized MSE): 1.4786420269983012\n"
     ]
    }
   ],
   "source": [
    "u,v, final_err = train_model(m, n, k, eta, reg, lst, eps=0.0001, max_epochs=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = np.loadtxt('data/train.txt').astype(int)\n",
    "Y_test = np.loadtxt('data/test.txt').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, E_in (regularized MSE): 3.5714589727368447\n",
      "Epoch 2, E_in (regularized MSE): 2.5333840359129285\n",
      "Epoch 3, E_in (regularized MSE): 2.1174466931852423\n",
      "Epoch 4, E_in (regularized MSE): 1.9011409562020862\n",
      "Epoch 5, E_in (regularized MSE): 1.813145853300226\n",
      "Epoch 6, E_in (regularized MSE): 1.7039875604007362\n",
      "Epoch 7, E_in (regularized MSE): 1.6809094630137984\n",
      "Epoch 8, E_in (regularized MSE): 1.6244684722267573\n",
      "Epoch 9, E_in (regularized MSE): 1.6009022790050338\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-2ee1f4bb1f91>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mreg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal_err\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-2078fe76ddce>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(M, N, K, eta, reg, Y, eps, max_epochs)\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0;31m# Run an epoch of SGD\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         \u001b[0mbefore_E_in\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_err\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mV\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m         \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mind\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-2078fe76ddce>\u001b[0m in \u001b[0;36mget_err\u001b[0;34m(U, V, Y, reg)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0merr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mYij\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0merr\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m0.5\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mYij\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mU\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mV\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m     \u001b[0;31m# Add error penalty due to regularization if regularization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;31m# parameter is nonzero\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_movies = len(movie_dic)\n",
    "num_users = 943\n",
    "m = num_users\n",
    "n = num_movies\n",
    "k = 20\n",
    "eta = 0.1\n",
    "reg = 0.1\n",
    "\n",
    "u,v, final_err = train_model(m, n, k, eta, reg, Y_train, eps=0.0001, max_epochs=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_in = get_err(u, v, Y_train)\n",
    "e_out = get_err(u, v, Y_test)\n",
    "print(\"e_in is: \" + str(e_in))\n",
    "print(\"e_out is: \" + str(e_out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVD visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "svd = TruncatedSVD(n_components=2, n_iter=7, random_state=42)\n",
    "svd.fit_transform(v)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.linalg import svd\n",
    "a, sigma, b = np.linalg.svd(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.diag(sigma).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = a[:, :2].T\n",
    "print(transformer.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_v = np.matmul(transformer, v).T\n",
    "print(transformed_v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_u = np.matmul(transformer, u.T).T\n",
    "print(transformed_u.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.random.randint(1682, size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [transformed_v[i][0] for i in indices]\n",
    "y = [transformed_v[i][1] for i in indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_ratings_vs_movies = [0 for i in movie_dic.keys()]\n",
    "for (i, j, yij) in lst:\n",
    "    num_ratings_vs_movies[j] += 1\n",
    "num_ratings_vs_movies = np.array(num_ratings_vs_movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = num_ratings_vs_movies.argsort()[-10:][::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [transformed_v[i][0] for i in indices]\n",
    "y = [transformed_v[i][1] for i in indices]\n",
    "plt.scatter(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_rating_dic = {id: [] for id in movie_dic.keys()} # dic of movie id and ratings\n",
    "\n",
    "for rating in lst:\n",
    "    _, movie_id, r = rating\n",
    "    movie_rating_dic[movie_id].append(r)\n",
    "\n",
    "avg_ratings = {movie: sum(movie_rating_dic[movie]) / len(movie_rating_dic[movie]) \\\n",
    "               for movie in movie_rating_dic}\n",
    "\n",
    "# get ten best movies that received highest average rating\n",
    "top_10 = sorted(avg_ratings.items(), key=lambda tup: tup[1], reverse=True)[:10]\n",
    "indices = [t[0] for t in top_10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [transformed_v[i][0] for i in indices]\n",
    "y = [transformed_v[i][1] for i in indices]\n",
    "plt.scatter(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fant_movies = movie_genre_dic['Fantasy']\n",
    "indices = fant_movies[:10]\n",
    "x = [transformed_v[i][0] for i in indices]\n",
    "y = [transformed_v[i][1] for i in indices]\n",
    "plt.scatter(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fant_movies = movie_genre_dic['Documentary']\n",
    "indices = fant_movies[:10]\n",
    "x = [transformed_v[i][0] for i in indices]\n",
    "y = [transformed_v[i][1] for i in indices]\n",
    "plt.scatter(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fant_movies = movie_genre_dic[\"Children's\"]\n",
    "indices = fant_movies[:10]\n",
    "x = [transformed_v[i][0] for i in indices]\n",
    "y = [transformed_v[i][1] for i in indices]\n",
    "plt.scatter(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
